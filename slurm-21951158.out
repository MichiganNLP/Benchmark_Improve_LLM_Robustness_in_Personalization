Found 4 chunk files. Aggregating results...
Deleted: results/mcq_results/Mistral-7B-Instruct-v0.3_commonsense_qa_2.csv
Deleted: results/mcq_results/Mistral-7B-Instruct-v0.3_commonsense_qa_1.csv
Deleted: results/mcq_results/Mistral-7B-Instruct-v0.3_commonsense_qa_0.csv
Deleted: results/mcq_results/Mistral-7B-Instruct-v0.3_commonsense_qa_3.csv
profile_0_answer_accuracy: 69.21%
profile_1_answer_accuracy: 53.40%
profile_2_answer_accuracy: 41.28%
profile_3_answer_accuracy: 59.21%
profile_4_answer_accuracy: 52.99%
profile_5_answer_accuracy: 54.95%
profile_6_answer_accuracy: 62.57%
profile_7_answer_accuracy: 62.08%
profile_8_answer_accuracy: 61.10%
profile_9_answer_accuracy: 64.37%
profile_10_answer_accuracy: 58.97%
lenght of final df is 1221
Aggregated results saved at: results/mcq_results/Mistral-7B-Instruct-v0.3_commonsense_qa_final.csv
