{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11879e78",
   "metadata": {},
   "source": [
    "# Aggregate multiple datasets to one\n",
    "\n",
    "Thsi section defines some stuff for running the script. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15f0c146",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import zipfile\n",
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "# -----------------------------\n",
    "# Global variables\n",
    "# -----------------------------\n",
    "# List of models (as provided)\n",
    "MODELS_FULL = [\n",
    "    \"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    \"kaist-ai/janus-7b\",\n",
    "    \"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
    "    # \"meta-llama/Llama-3.3-70B-Instruct\",\n",
    "    \"mistralai/Mistral-7B-Instruct-v0.3\",\n",
    "]\n",
    "# Process model names\n",
    "MODELS = [model.split(\"/\")[-1] for model in MODELS_FULL]\n",
    "\n",
    "# Prompt methods to process\n",
    "PROMPT_METHODS = [\"cot\", \"direct\", \"icl\"]\n",
    "\n",
    "# The input dataset directories (each should contain a CSV per model)\n",
    "DATASETS_FULL = [\n",
    "    \"tau/commonsense_qa\",\n",
    "    \"cais/mmlu\",\n",
    "    \"truthfulqa/truthful_qa\",\n",
    "]\n",
    "# Process dataset names\n",
    "DATASETS = [dataset.split(\"/\")[-1] for dataset in DATASETS_FULL]\n",
    "\n",
    "DATASET_LENS = {\n",
    "    \"commonsense_qa\": 1221,\n",
    "    \"mmlu\": 5170,\n",
    "    \"truthful_qa\": 817,\n",
    "}\n",
    "\n",
    "# The target output subdirectory (under each prompt method) where aggregated results are saved.\n",
    "TARGET_DATASET = \"full\"\n",
    "# The robust dataset to use for aggregation\n",
    "ROBUST_PATH = os.path.join(\"data\", \"robuset.csv\")\n",
    "\n",
    "from preferences.prefs import MMLU_PREFS, TQA_PREFS, CQA_PREFS\n",
    "\n",
    "DATASET_PREFERENCES = {\n",
    "  \"tau/commonsense_qa\": CQA_PREFS,\n",
    "  \"cais/mmlu\": MMLU_PREFS,\n",
    "  \"truthfulqa/truthful_qa\": TQA_PREFS,\n",
    "  \"commonsense_qa\": CQA_PREFS,\n",
    "  \"mmlu\": MMLU_PREFS,\n",
    "  \"truthful_qa\": TQA_PREFS,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e45ff8",
   "metadata": {},
   "source": [
    "## Check if for all models/method, all files exist\n",
    "\n",
    "This part checks if all datasets (configured above) exists one and only one csv files for a particular (prompt method, model) pair, and whether it has the same length. Stats are printed for missing files for each combination, so you know which runs are still missing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "124a24d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Warning: No files found for [cot, Llama-3.1-8B-Instruct, commonsense_qa]\n",
      "Warning: No files found for [cot, Llama-3.1-8B-Instruct, mmlu]\n",
      "Warning: No files found for [cot, Llama-3.1-8B-Instruct, truthful_qa]\n",
      "Incomplete files for [cot, Llama-3.1-8B-Instruct]\n",
      "\n",
      "Warning: No files found for [cot, janus-7b, commonsense_qa]\n",
      "Warning: No files found for [cot, janus-7b, mmlu]\n",
      "Warning: No files found for [cot, janus-7b, truthful_qa]\n",
      "Incomplete files for [cot, janus-7b]\n",
      "\n",
      "Warning: No files found for [cot, Mixtral-8x7B-Instruct-v0.1, commonsense_qa]\n",
      "Warning: No files found for [cot, Mixtral-8x7B-Instruct-v0.1, mmlu]\n",
      "Warning: No files found for [cot, Mixtral-8x7B-Instruct-v0.1, truthful_qa]\n",
      "Incomplete files for [cot, Mixtral-8x7B-Instruct-v0.1]\n",
      "\n",
      "Warning: No files found for [cot, Mistral-7B-Instruct-v0.3, commonsense_qa]\n",
      "Warning: No files found for [cot, Mistral-7B-Instruct-v0.3, mmlu]\n",
      "Warning: No files found for [cot, Mistral-7B-Instruct-v0.3, truthful_qa]\n",
      "Incomplete files for [cot, Mistral-7B-Instruct-v0.3]\n",
      "\n",
      "Warning: No files found for [direct, Llama-3.1-8B-Instruct, commonsense_qa]\n",
      "Warning: No files found for [direct, Llama-3.1-8B-Instruct, mmlu]\n",
      "Warning: No files found for [direct, Llama-3.1-8B-Instruct, truthful_qa]\n",
      "Incomplete files for [direct, Llama-3.1-8B-Instruct]\n",
      "\n",
      "Warning: No files found for [direct, janus-7b, commonsense_qa]\n",
      "Warning: No files found for [direct, janus-7b, mmlu]\n",
      "Warning: No files found for [direct, janus-7b, truthful_qa]\n",
      "Incomplete files for [direct, janus-7b]\n",
      "\n",
      "Warning: No files found for [direct, Mixtral-8x7B-Instruct-v0.1, commonsense_qa]\n",
      "Warning: No files found for [direct, Mixtral-8x7B-Instruct-v0.1, mmlu]\n",
      "Warning: No files found for [direct, Mixtral-8x7B-Instruct-v0.1, truthful_qa]\n",
      "Incomplete files for [direct, Mixtral-8x7B-Instruct-v0.1]\n",
      "\n",
      "Warning: No files found for [direct, Mistral-7B-Instruct-v0.3, commonsense_qa]\n",
      "Warning: No files found for [direct, Mistral-7B-Instruct-v0.3, mmlu]\n",
      "Warning: No files found for [direct, Mistral-7B-Instruct-v0.3, truthful_qa]\n",
      "Incomplete files for [direct, Mistral-7B-Instruct-v0.3]\n",
      "\n",
      "Warning: No files found for [icl, Llama-3.1-8B-Instruct, commonsense_qa]\n",
      "Warning: No files found for [icl, Llama-3.1-8B-Instruct, mmlu]\n",
      "Warning: No files found for [icl, Llama-3.1-8B-Instruct, truthful_qa]\n",
      "Incomplete files for [icl, Llama-3.1-8B-Instruct]\n",
      "\n",
      "Warning: No files found for [icl, janus-7b, commonsense_qa]\n",
      "Warning: No files found for [icl, janus-7b, mmlu]\n",
      "Warning: No files found for [icl, janus-7b, truthful_qa]\n",
      "Incomplete files for [icl, janus-7b]\n",
      "\n",
      "Warning: No files found for [icl, Mixtral-8x7B-Instruct-v0.1, commonsense_qa]\n",
      "Warning: No files found for [icl, Mixtral-8x7B-Instruct-v0.1, mmlu]\n",
      "Warning: No files found for [icl, Mixtral-8x7B-Instruct-v0.1, truthful_qa]\n",
      "Incomplete files for [icl, Mixtral-8x7B-Instruct-v0.1]\n",
      "\n",
      "Warning: No files found for [icl, Mistral-7B-Instruct-v0.3, commonsense_qa]\n",
      "Warning: No files found for [icl, Mistral-7B-Instruct-v0.3, mmlu]\n",
      "Warning: No files found for [icl, Mistral-7B-Instruct-v0.3, truthful_qa]\n",
      "Incomplete files for [icl, Mistral-7B-Instruct-v0.3]\n",
      "Found 0/12 valid combinations:\n"
     ]
    }
   ],
   "source": [
    "valid_combinations = []\n",
    "\n",
    "# First, verify the robust dataset exists.\n",
    "if not os.path.exists(ROBUST_PATH):\n",
    "    print(f\"Robust dataset not found at {ROBUST_PATH}. Exiting.\")\n",
    "    exit(0)\n",
    "robust_df = pd.read_csv(ROBUST_PATH)\n",
    "robust_rows = len(robust_df)\n",
    "\n",
    "def detect_and_add(method, dataset, model, combo_files):\n",
    "    file_pattern1 = os.path.join(\"results\", \"mcq_results\", \"relevant\", method, dataset, model+\"*_eval.csv\")\n",
    "    file_pattern2 = os.path.join(\"results\", \"mcq_results\", \"relevant\", method, dataset, model+\"_eval.csv\")\n",
    "    # print(f\"Checking {file_pattern1} and {file_pattern2}\")\n",
    "    files = list(set(glob.glob(file_pattern1) + glob.glob(file_pattern2)))\n",
    "    if files:\n",
    "        if len(files) > 1:\n",
    "            print(f\"Warning: Multiple files found for [{method}, {model}, {dataset}]. Check combination\")\n",
    "            return False\n",
    "        combo_files.append(files[0])\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# Check all files exist\n",
    "for method, model in itertools.product(PROMPT_METHODS, MODELS):\n",
    "    # print(f\"\\nChecking {method}, {model}\")\n",
    "    print(\"\")\n",
    "    combo_files = []\n",
    "    for dataset in DATASETS:\n",
    "        if detect_and_add(method, dataset, model, combo_files):\n",
    "            continue\n",
    "        # Otherwise, try the zipped version\n",
    "        zip_file = os.path.join(\"results\", \"mcq_results\", \"relevant\", method, dataset, model+\".zip\")\n",
    "        if os.path.exists(zip_file):\n",
    "            with zipfile.ZipFile(zip_file, \"r\") as zip_ref:\n",
    "                zip_ref.extractall(os.path.join(\"results\", \"mcq_results\", \"relevant\", method, dataset))\n",
    "            if detect_and_add(method, dataset, model, combo_files):\n",
    "                continue\n",
    "        print(f\"Warning: No files found for [{method}, {model}, {dataset}]\")\n",
    "        continue\n",
    "    if len(combo_files) != len(DATASETS):\n",
    "        print(f\"Incomplete files for [{method}, {model}]\")\n",
    "        continue\n",
    "    # Add to valid combinations\n",
    "    valid_combinations.append((method, model, combo_files))\n",
    "    print(f\"Completed files for {method}, {model}\")\n",
    "\n",
    "print(f\"Found {len(valid_combinations)}/{len(PROMPT_METHODS)*len(MODELS)} valid combinations:\")\n",
    "for method, model, combo_files in valid_combinations:\n",
    "    print(f\" - {method}, {model}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e312ba0c",
   "metadata": {},
   "source": [
    "# Remove existing aggregations, if in conflict\n",
    "\n",
    "This section can be turned on to skip combinations that already have a full version exist. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78c4da62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "To be prrocessed: 0/12 combinations\n"
     ]
    }
   ],
   "source": [
    "SKIP_EXISTING = True\n",
    "\n",
    "if SKIP_EXISTING:\n",
    "    still_valid_combinations = []\n",
    "    for (method, model, combo_files) in valid_combinations:\n",
    "        goal_dataset_path = os.path.join(\"results\", \"mcq_results\", \"relevant\", method, \"full\", f\"{model}-{method}-full_eval.csv\")\n",
    "        if os.path.exists(goal_dataset_path):\n",
    "            exist_df = pd.read_csv(goal_dataset_path)\n",
    "            exist_rows = len(exist_df)\n",
    "            if exist_rows == robust_rows:\n",
    "                print(f\"Skipping {method}, {model} as it already exists.\")\n",
    "                continue\n",
    "            else:\n",
    "                print(f\"Warning: {method}, {model} exists but has {exist_rows}/{robust_rows} rows. Overwriting.\")\n",
    "        else:\n",
    "            print(f\"Processing {method}, {model}\")\n",
    "        still_valid_combinations.append((method, model, combo_files))\n",
    "    valid_combinations = still_valid_combinations\n",
    "\n",
    "print(f\"\\nTo be prrocessed: {len(valid_combinations)}/{len(PROMPT_METHODS)*len(MODELS)} combinations\")\n",
    "for method, model, combo_files in valid_combinations:\n",
    "    print(f\" - {method}, {model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648b2b9e",
   "metadata": {},
   "source": [
    "For each combination, process the data and match with existing robust_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2801579",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (method, model, combo_files) in valid_combinations:\n",
    "    processed_dfs = []\n",
    "    goal_dataset_path = os.path.join(\"results\", \"mcq_results\", \"relevant\", method, \"full\", f\"{model}-{method}-full_eval.csv\")\n",
    "    for combo_file, dataset, full_dataset in zip(combo_files, DATASETS, DATASETS_FULL):\n",
    "        print(f\"Processing {method}, {model}, {dataset}\")\n",
    "        data_df = pd.read_csv(combo_file)\n",
    "        # Get chunk from robust_df\n",
    "        robust_chunk = robust_df[robust_df[\"source\"] == full_dataset].copy()\n",
    "        assert len(data_df)==len(robust_chunk), \"Sizes don't match!\"\n",
    "\n",
    "        data_df = data_df.sort_values(by=[\"question\", \"options\"]).reset_index(drop=True)\n",
    "        robust_chunk = robust_chunk.sort_values(by=[\"question\", \"options\"]).reset_index(drop=True)\n",
    "        # Check size\n",
    "        assert len(data_df)==len(robust_chunk), \"Sizes don't match!\"\n",
    "\n",
    "        # Assert correct answers\n",
    "        data_correct_ans = data_df[\"gold_option\"].reset_index(drop=True)\n",
    "        robust_correct_ans = robust_chunk[\"gold_option\"].reset_index(drop=True)\n",
    "        assert len(data_correct_ans)==len(robust_correct_ans), \"Option Sizes don't match!\"\n",
    "\n",
    "        pref_library = DATASET_PREFERENCES.get(full_dataset, {})\n",
    "        # Reverse the TQA_PREFS dictionary: keys become values and vice versa.\n",
    "        rev_prefs = {v: k for k, v in pref_library.items()}\n",
    "\n",
    "        # create a new column \"pref_index\" that maps the text to its corresponding index.\n",
    "        robust_chunk[\"pref_index\"] = robust_chunk.loc[:,\"preference\"].map(rev_prefs)\n",
    "        pref_text = robust_chunk.apply(\n",
    "            lambda row: pref_library[int(row['pref_index'])],\n",
    "            axis=1\n",
    "        )\n",
    "        pref_res = robust_chunk.apply(\n",
    "            lambda row: data_df.loc[row.name, f\"profile_{int(row['pref_index'])}_res\"],\n",
    "            axis=1\n",
    "        )\n",
    "        pref_answer = robust_chunk.apply(\n",
    "            lambda row: data_df.loc[row.name, f\"profile_{int(row['pref_index'])}_answer\"],\n",
    "            axis=1\n",
    "        )\n",
    "        pref_correct = pref_answer.eq(data_df[\"gold_option\"])\n",
    "        nopref_res = robust_chunk.apply(\n",
    "            lambda row: data_df.loc[row.name, f\"profile_0_res\"],\n",
    "            axis=1\n",
    "        )\n",
    "        nopref_answer = robust_chunk.apply(\n",
    "            lambda row: data_df.loc[row.name, f\"profile_0_answer\"],\n",
    "            axis=1\n",
    "        )\n",
    "        nopref_correct = nopref_answer.eq(data_df[\"gold_option\"])\n",
    "        # Start building a new dataframe\n",
    "        new_df_dict = {\n",
    "            \"question\": data_df[\"question\"],\n",
    "            \"options\": data_df[\"options\"],\n",
    "            \"gold_option\": data_df[\"gold_option\"],\n",
    "            \"source\": robust_chunk[\"source\"],\n",
    "            \"profile_idx\": robust_chunk[\"pref_index\"],\n",
    "            \"preference\": pref_text,\n",
    "            \"pref_res\": pref_res,\n",
    "            \"pref_answer\": pref_answer,\n",
    "            \"pref_correct\": pref_correct,\n",
    "            \"nopref_res\": nopref_res,\n",
    "            \"nopref_answer\": nopref_answer,\n",
    "            \"nopref_correct\": nopref_correct,\n",
    "        }\n",
    "        # print(\"Correctness rate:\", nopref_correct.mean(), pref_correct.mean())\n",
    "        processed_dfs.append(pd.DataFrame(new_df_dict))\n",
    "    \n",
    "    # Concatenate and save df\n",
    "    combined_df = pd.concat(processed_dfs, ignore_index=True)\n",
    "    assert len(combined_df)==robust_rows, \"Sizes don't match!\"\n",
    "    combined_df.to_csv(goal_dataset_path, index=False)\n",
    "    print(f\"Saved {method}, {model} to full\")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803bf95b",
   "metadata": {},
   "source": [
    "## Add correctness column if not exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5790102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added files for cot, Llama-3.1-8B-Instruct\n",
      "Added files for cot, janus-7b\n",
      "Added files for cot, Mixtral-8x7B-Instruct-v0.1\n",
      "Added files for cot, Mistral-7B-Instruct-v0.3\n",
      "Added files for direct, Llama-3.1-8B-Instruct\n",
      "Added files for direct, janus-7b\n",
      "Added files for direct, Mixtral-8x7B-Instruct-v0.1\n",
      "Added files for direct, Mistral-7B-Instruct-v0.3\n",
      "Added files for icl, Llama-3.1-8B-Instruct\n",
      "Added files for icl, janus-7b\n",
      "Added files for icl, Mixtral-8x7B-Instruct-v0.1\n",
      "Added files for icl, Mistral-7B-Instruct-v0.3\n",
      "Found 12/12 datasets to stats\n"
     ]
    }
   ],
   "source": [
    "# Create stats folder and compute stats\n",
    "stats_folder = os.path.join(\"results\", \"mcq_results\", \"relevant\",\"stats\")\n",
    "\n",
    "# For each method and model, try loading the full dataset\n",
    "# And compute robustness = (pref_correct / nopref_correct) given nopref_correct\n",
    "if not os.path.exists(stats_folder):\n",
    "    os.makedirs(stats_folder)\n",
    "\n",
    "# Rebuild valid combinations\n",
    "valid_combinations = []\n",
    "for method, model in itertools.product(PROMPT_METHODS, MODELS):\n",
    "    full_dataset_path = os.path.join(\"results\", \"mcq_results\", \"relevant\", method, \"full\", f\"{model}-{method}-full_eval.csv\")\n",
    "    if not os.path.exists(full_dataset_path):\n",
    "        print(f\"Warning: No full dataset found for [{method}, {model}]\")\n",
    "        # valid_combinations.append((method, model, None))\n",
    "        continue\n",
    "    # Add to valid combinations\n",
    "    valid_combinations.append((method, model, full_dataset_path))\n",
    "    print(f\"Added files for {method}, {model}\")\n",
    "\n",
    "    full_df = pd.read_csv(full_dataset_path)\n",
    "    if 'nopref_correct' not in full_df.columns:\n",
    "        full_df['nopref_correct'] = full_df[\"gold_option\"] == full_df[\"no_pref_ans\"]\n",
    "    if 'pref_correct' not in full_df.columns:\n",
    "        full_df['pref_correct'] = full_df[\"gold_option\"] == full_df[\"pref_ans\"]\n",
    "    full_df.to_csv(full_dataset_path, index=False)\n",
    "\n",
    "print(f\"Found {len(valid_combinations)}/{len(PROMPT_METHODS)*len(MODELS)} datasets to stats\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pref_aligner",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
